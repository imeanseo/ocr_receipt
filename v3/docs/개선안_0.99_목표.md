# 0.99 목표 개선안 (현재 ~0.984 기준)

현재 V3 ResNet50 기준 **hmean ~0.984**. 여기서 **0.99**까지 올리기 위한 수정 후보를 우선순위대로 정리했습니다.

---

## 1. 바로 시도해볼 만한 것 (구현 난이도 낮음)

### 1-1. 후처리 파라미터 튜닝 (thresh / box_thresh)
- **위치**: `configs/preset/models/head/db_head.yaml`
- **현재**: `thresh: 0.22`, `box_thresh: 0.35`
- **방법**: validation으로 그리드 서치
  - `thresh`: 0.18, 0.20, 0.22, 0.25
  - `box_thresh`: 0.30, 0.35, 0.40
- **참고**: Precision이 더 낮으면 `box_thresh` 올리기, Recall이 더 낮으면 `thresh`/`box_thresh` 내리기.

### 1-2. 학습량 늘리기
- **위치**: `configs/train.yaml`
- **변경**: `max_epochs: 20` → `25` 또는 `30`
- **함께**: `configs/preset/models/model_example.yaml`에서 `T_max: 20` → `T_max: 25` (또는 30)으로 CosineAnnealingLR에 맞춰 수정.

### 1-3. 해상도 1280 시험 (GPU 메모리 여유 있을 때)
- **위치**: `configs/preset/datasets/db.yaml`
- **변경**: `LongestMaxSize` / `PadIfNeeded` 의 `max_size`, `min_width`, `min_height` 를 **1024 → 1280**
- **주의**: OOM 나면 `batch_size` 6→4, `accumulate_grad_batches` 3→4 등으로 effective batch 유지.

---

## 2. 모델 쪽 변경 (효과 크지만 설정/코드 수정 필요)

### 2-1. 백본 업그레이드 (ResNet101)
- **위치**: `configs/preset/models/encoder/timm_backbone.yaml`
- **변경**: `model_name: 'resnet50'` → `'resnet101'`
- **디코더**: ResNet101도 C2~C5 채널 수가 256, 512, 1024, 2048 이므로 **`configs/preset/models/decoder/unet.yaml` 은 그대로 두면 됨.**

### 2-2. Augmentation 강화
- **위치**: `configs/preset/datasets/db.yaml` → `transforms.train_transform.transforms`
- **추가 예시**:
  - `GaussianBlur`: 블러로 로버스트니스
  - `GaussNoise`: 노이즈
  - `RandomResizedCrop` 또는 `ShiftScaleRotate`: 스케일/회전 다양화
- 기존 Augmentation 비율(`p`)을 조금 올리거나, 위 항목을 소폭(`p=0.2~0.3`)으로 넣어서 과적합만 안 나게 조절.

### 2-3. Loss 가중치 미세 조정
- **위치**: `configs/preset/models/loss/db_loss.yaml`
- **현재**: `prob_map_loss_weight: 7.0`, `thresh_map_loss_weight: 10.0`, `binary_map_loss_weight: 1.0`
- **시도**: `prob_map_loss_weight` 8.0~10.0 구간에서 1~2번 바꿔 보며 val hmean 확인.

---

## 3. 제출 단계에서만 쓸 수 있는 것

### 3-1. TTA (Test-Time Augmentation)
- **방법**: 예측 시 원본 + 좌우 반전(또는 다중 스케일)으로 inference 후, 반전 결과를 다시 뒤집어서 원본 좌표로 맞춘 뒤 **같은 이미지에 대해 여러 예측을 합침** (예: 확률맵 평균 또는 박스 NMS/병합).
- **구현**: `runners/predict.py` 또는 별도 TTA 스크립트에서 이미지 복제·변환 → 예측 → 역변환 → 병합. 코드 수정 필요.

### 3-2. 앙상블
- **방법**: epoch 15 + epoch 19(마지막) 체크포인트 각각으로 예측한 **확률맵을 평균**한 뒤 동일 후처리(thresh/box_thresh) 적용.
- **효과**: 같은 모델이라도 0.5~1%p 정도 hmean 상승 기대 가능.

---

## 4. 적용 순서 제안

| 순서 | 항목 | 예상 효과 | 비고 |
|------|------|-----------|------|
| 1 | thresh / box_thresh 그리드 서치 | +0.2~0.5%p | 학습 없이 바로 가능 |
| 2 | max_epochs 25~30, T_max 맞추기 | +0.1~0.3%p | 재학습 1회 |
| 3 | 해상도 1280 (batch 조정) | +0.2~0.5%p | 메모리 확인 |
| 4 | ResNet101 백본 | +0.2~0.4%p | 디코더 설정 동일 |
| 5 | TTA 또는 앙상블 | +0.3~0.6%p | 추론/제출 파이프라인 수정 |

**정리**: 1→2→3 또는 1→2→4 까지 적용해 보면서 val hmean을 보고, 아직 부족하면 5(TTA/앙상블)를 검토하는 흐름을 추천합니다.

---

## 5. 체크리스트 (수정 시 확인)

- [ ] 후처리: `db_head.yaml` → thresh, box_thresh
- [ ] 학습: `train.yaml` → max_epochs / `model_example.yaml` → T_max
- [ ] 해상도: `db.yaml` → max_size, min_width, min_height (및 batch_size/accumulate)
- [ ] 백본: `timm_backbone.yaml` → model_name (resnet101 시 디코더 in_channels 유지)
- [ ] Loss: `db_loss.yaml` → prob_map_loss_weight 등

위 항목들을 조합해 보면 0.99에 근접하거나 도달할 가능성이 높습니다.
