# @package _global_

defaults:
  - /preset/models/decoder/unet
  - /preset/models/encoder/timm_backbone
  - /preset/models/head/db_head
  - /preset/models/loss/db_loss
  - _self_

models:
  optimizer:
    _target_: torch.optim.AdamW
    lr: 0.001
    weight_decay: 0.0001
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 20                    # CosineAnnealingLR 사용 (더 부드러운 학습)
    eta_min: 1e-6
